# AUTOGENERATED! DO NOT EDIT! File to edit: 00_core.ipynb (unless otherwise specified).

__all__ = ['DotPathDict', 'request_to_cache_file', 'request_from_github', 'CachedResponse', 'requests_get',
           'FhirClient', 'get_all_entries', 'get_all_resources', 'get_by_reference', 'extract_patient_ids',
           'intersection_patient_ids', 'find_by_key']

# Cell
import requests, json, datetime, collections, typing, urllib
from pathlib import Path
from fastcore.basics import patch_to

# Cell
class DotPathDict(collections.UserDict):
    "Wraps a `dict` to allow simple dot notation search of nested `dict`s"

    def __getitem__(self, dot_paths):
        "Allows dot search via subscript"
        for dot_path in dot_paths.split(' OR '):
            data, found = self.data, True
            path_parts = dot_path.split('.')
            for path_part_idx, path_part in enumerate(path_parts):
                if not isinstance(data, (dict, DotPathDict)):
                    path_parts = '.'.join(path_parts[:path_part_idx])
                    raise Exception(f'Expected "{path_parts}" to be a `dict` but found {type(data)} {data}')
                if not path_part in data:
                    found = False
                    break # try the next dot_path, if we have one
                data = data[path_part]
                if isinstance(data, list) and len(data) > 0:
                    found_next_path_part = False
                    if path_part_idx < len(path_parts) - 1:
                        next_path_part = path_parts[path_part_idx + 1]
                        for potential_data in data:
                            if next_path_part in potential_data:
                                data = potential_data
                                found_next_path_part = True
                                break
                    if not found_next_path_part:
                        data = data[0]
            if found:
                return DotPathDict(data) if isinstance(data, dict) else data

# Cell
def request_to_cache_file(url, params):
    "Return the local file that is or should be used to cache the request"
    parsed_url = urllib.parse.urlparse(url)
    cache_folder = Path('data/cache/')/parsed_url.netloc.replace(':', '-')
    cache_index = {}
    if (cache_folder/'index.json').is_file():
        with open(cache_folder/'index.json') as f:
            cache_index = json.load(f)
    cache_key = url if params is None else f'{url}?{urllib.parse.urlencode(params)}'
    if cache_key in cache_index:
        return cache_folder/cache_index[cache_key]
    cache_index[cache_key] = f'''{parsed_url.path.replace('/', '')}-{len(cache_index)}'''
    cache_folder.mkdir(parents=True, exist_ok=True)
    with open(cache_folder/'index.json', 'w') as f:
        json.dump(cache_index, f, indent=2)
    return cache_folder/cache_index[cache_key]

# Cell
def request_from_github(url, params):
    "GET a cached response from github"
    netloc = urllib.parse.urlparse(url).netloc
    raw_branch = 'https://raw.githubusercontent.com/pete88b/vulcan_rwd_ig/main'
    response = requests.get(f'{raw_branch}/data/cache/{netloc}/index.json')
    print('GET', response.url, 'Status', response.status_code)
    cache_index = response.json()
    cache_key = url if params is None else f'{url}?{urllib.parse.urlencode(params)}'
    if cache_key not in cache_index:
        raise Exception(f'Query not cached in github: {cache_key} not in {response.url}')
    return requests.get(f'{raw_branch}/data/cache/{netloc}/{cache_index[cache_key]}')

# Cell
class CachedResponse:
    "Looks like an HTTP response but loads a locally cached response instead"
    def __init__(self, cache_file):
        self.status_code = 200
        with open(cache_file) as f:
            self.text = f.read()
    def json(self):
        return json.loads(self.text)

# Cell
def requests_get(url, params, headers=None, use_local_cache=True):
    "Returns an HTTP response from local cache, FHIR server or github"
    if use_local_cache:
        cache_file = request_to_cache_file(url, params)
        if cache_file.is_file():
            print('GET', cache_file, 'from local cache')
            return CachedResponse(cache_file)
    # HTTP GET from a real FHIR server
    response = requests.get(url, params, headers=headers)
    print('GET', response.url, 'Status', response.status_code)
    if not response.status_code:
        # HTTP GET from github if the real server doesn't return a successful response
        response = request_from_github(url, params)
        print('GET', response.url, 'Status', response.status_code)
    # cache the result returned by the real FHIR server
    if use_local_cache and response.status_code == 200:
        cache_file.parent.mkdir(parents=True, exist_ok=True)
        with open(cache_file, 'w', encoding='utf8') as f:
            f.write(response.text)
    return response

# Cell
class FhirClient:
    "Helps to GET FHIR resources"
    def __init__(self, api_base:str, x_api_key:str=None, use_local_cache=True):
        self.api_base = api_base
        self.use_local_cache = use_local_cache
        self.request_headers = {}
        if x_api_key is not None:
            self.request_headers['x-api-key'] = x_api_key
        self.default_params = {}

    def get_as_raw_json(self, resource_type:str, params:dict=None) -> dict:
        "GET FHIR resources of `resource_type` in JSON format"
        url = f'{self.api_base}/{resource_type}'
        params = self.default_params if params is None else params
        return requests_get(url, params, self.request_headers, self.use_local_cache).json()

    def get_next_as_raw_json(self, json_response:dict) -> dict:
        "GET the next set of results"
        if 'link' not in json_response:
            return None
        for link in json_response['link']:
            if link['relation'] == 'next':
                url = link['url']
                response = requests_get(url, None, self.request_headers, self.use_local_cache)
                print('GET', url, 'Status', response.status_code)
                return response.json()

# Cell
@patch_to(FhirClient)
def get_all_entries(self, resource_type:str, params:dict=None, page_limit:int=100) -> typing.List[DotPathDict]:
    "Return a list of entries of `resource_type` in JSON format while taking care of bundle pageing"
    page_count, result = 0, []
    bundle = self.get_as_raw_json(resource_type, params)
    total = bundle.get('total', 'Unknown')
    if total == 0:
        print('Returning', len(result), 'entries')
        return result
    while bundle is not None:
        if bundle.get('resourceType', None) != 'Bundle':
            raise Exception(f'Expected a bundle but found', bundle) # might be {'resourceType': 'OperationOutcome' ...
        result.extend(bundle['entry']) # todo check for OperationOutcome etc in `entry`
        page_count += 1
        if page_count > page_limit:
            print('Stopping early. Will return', len(result), 'entries out of total', total)
            break
        bundle = self.get_next_as_raw_json(bundle)
    def _expected_resource_type(resource):
        actual_resource_type = resource.get('resource', {}).get('resourceType', None)
        if actual_resource_type != resource_type:
            print('Removing resource. Expected', resource_type, 'but found', actual_resource_type)
            return False
        return True
    result = [r for r in result if _expected_resource_type(r)]
    result = [DotPathDict(r) for r in result]
    print('Returning', len(result), 'entries')
    return result

@patch_to(FhirClient)
def get_all_resources(self, resource_type:str, params:dict=None, page_limit:int=100):
    "Return a list of resources of `resource_type` in JSON format"
    result = self.get_all_entries(resource_type, params, page_limit)
    result = [r['resource'] for r in result]
    return result

@patch_to(FhirClient)
def get_by_reference(self, reference:str):
    "Return a resource read from a FHIR server by reference, as a list containg a single bundle entry"
    if reference.startswith(self.api_base):
        reference = reference[len(self.api_base):].strip('/')
    if reference.startswith('http'):
        print(f'WARNING: Found reference {reference} that does not start with {api_base}')
        return []
    resource_type, id = reference.split('/')
    single_resource = self.get_as_raw_json(resource_type, id)
    return [dict(fullUrl = f'{self.api_base}/{resource_type}/{id}', resource = single_resource)]

# Cell
def extract_patient_ids(resources):
    "Return a list relative references of all patients found in a `resources`"
    # Note: no checks are made that the bundle contains resources of the same type etc
    result = []
    for resource in resources:
        if resource['resourceType'] == 'OperationOutcome':
            continue # e.g. "Unrecognized parameter 'dischargeDisposition'. exp"
        if resource['resourceType'] == 'Patient':
            result.append('Patient/' + resource['id'])
        else:
            result.append(resource['subject.reference OR patient.reference'])
    return result

# Cell
def intersection_patient_ids(*resource_lists):
    "Returns a list of references for all patients found in all resource lists"
    all_patient_ids = []
    for resource_list in resource_lists:
        all_patient_ids.append(extract_patient_ids(resource_list))
    all_patient_ids = [set(ids) for ids in all_patient_ids]
    result = all_patient_ids[0]
    for ids in all_patient_ids[1:]:
        result = result & ids
    return list(result)

# Cell
def _find_by_key(d, k, result):
    if isinstance(d, dict):
        for _k, _v in d.items():
            if _k == k:
                result.append(_v)
            _find_by_key(_v, k, result)
    elif isinstance(d, list):
        for _v in d:
            _find_by_key(_v, k, result)
    return result

def find_by_key(d:dict, k:str):
    "Return a list of values that we're keyed by `k` at any level in `d`"
    return _find_by_key(d, k, [])